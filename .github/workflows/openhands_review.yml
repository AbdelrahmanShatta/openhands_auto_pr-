name: OpenHands Code Quality Review

# [Previous steps remain the same until the OpenHands Review step]

      - name: Run OpenHands Review
        id: openhands_review
        if: env.BLACK_PASSED == 'true' && env.RUFF_PASSED == 'true' && env.MYPY_PASSED == 'true'
        env:
          WORKSPACE_BASE: ${{ github.workspace }}
          LLM_MODEL: "anthropic/claude-3-5-sonnet-20241022"
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          # Setup environment
          mkdir -p ${GITHUB_WORKSPACE}/.openhands-state
          chmod -R 777 ${GITHUB_WORKSPACE}/.openhands-state

          # Get PR details via GitHub API
          PR_FILES=$(curl -s -H "Authorization: Bearer $GITHUB_TOKEN" \
            -H "Accept: application/vnd.github.v3+json" \
            "https://api.github.com/repos/${{ github.repository }}/pulls/${{ github.event.pull_request.number }}/files")

          # Format task instruction
          TASK_INSTRUCTION="Review PR #${{ github.event.pull_request.number }} in ${{ github.repository }} according to .openhands_instructions. Output EXACTLY 'GOOD' or 'BAD'. PR changes: $PR_FILES"

          # Create a named pipe for input
          PIPE_PATH=$(mktemp -u)
          mkfifo "$PIPE_PATH"
          
          # Start background process to feed empty lines
          while true; do echo ''; sleep 1; done > "$PIPE_PATH" &
          FEED_PID=$!

          # Run OpenHands with input from the pipe
          docker run --rm \
            --user root \
            -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.24-nikolaik \
            -e SANDBOX_USER_ID=$(id -u) \
            -e WORKSPACE_MOUNT_PATH=$WORKSPACE_BASE \
            -e LLM_API_KEY=${{ secrets.LLM_API_KEY }} \
            -e LLM_MODEL=$LLM_MODEL \
            -e LOG_ALL_EVENTS=true \
            -v $WORKSPACE_BASE:/opt/workspace_base \
            -v /var/run/docker.sock:/var/run/docker.sock \
            -v ${GITHUB_WORKSPACE}/.openhands-state:/.openhands-state \
            --add-host host.docker.internal:host-gateway \
            docker.all-hands.dev/all-hands-ai/openhands:0.24 \
            python -m openhands.core.main \
            -t "$TASK_INSTRUCTION" \
            --eval-output-dir ./eval_output \
            -i 50 \
            -b 50 \
            --eval-n-limit 50 < "$PIPE_PATH" > openhands_output.log 2>&1

          # Clean up
          kill $FEED_PID
          rm "$PIPE_PATH"

          # More robust result parsing
          if grep -E "thought.*GOOD" openhands_output.log || grep -E "\[Agent Controller.*GOOD" openhands_output.log; then
            echo "OPENHANDS_PASSED=true" >> $GITHUB_ENV
          else
            echo "OPENHANDS_PASSED=false" >> $GITHUB_ENV
          fi

# [Rest of the workflow remains the same]
